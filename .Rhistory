anno <- select(anno,Symbol, Entrez_Gene_ID,Chromosome,Cytoband)
efit$genes <- anno
kable(topTable(efit), booktabs=T)%>%
kable_styling(latex_options= c("scale_down", "hold_position"))
full_results <- topTable(efit, number=Inf)
full_results <- tibble::rownames_to_column(full_results, "ID")
ggplot(full_results, aes(x=logFC, y=B)) +
geom_point()
p_cutoff <- 0.05
fc_cutoff <- 1
topN <- 20
full_results %>%
mutate(Significant = adj.P.Val < p_cutoff, abs(logFC) > fc_cutoff) %>%
mutate(Rank= 1:n(), Label= ifelse(Rank < topN, Symbol, "")) %>%
ggplot(aes(x = logFC, y=B, col=Significant, label= Label)) +
geom_text_repel(col="black")
#visualise
plotSA(efit, main="Final model: Mean-variance trend")
kable(topTable(efit), booktabs=T)%>%
kable_styling(latex_options=c("scale_down", "hold_position"))
tfit <- treat(efit, lfc=1)
dt <- decideTests(tfit)
kable(summary(dt), booktabs=T)%>%
kable_styling(latex_options= "hold_position")
adeno_vs_non <- topTreat(tfit, coef=1, n=Inf)
kable(head(adeno_vs_non), booktabs=T) %>%
kable_styling(latex_options= c("scale_down", "hold_position"))
plotMD(tfit, column=1, status=dt[,1], main=colnames(tfit)[1],
xlim=c(2,16))
kable(filter(full_results, Symbol == "SLC22A1"), booktabs=T)%>%
kable_styling(latex_options=c("scale_down", "hold_position"))
kable(filter(full_results, Symbol == "SLC22A4"), booktabs=T)%>%
kable_styling(latex_options=c("scale_down", "hold_position"))
kable(filter(full_results, Symbol == "SLC22A5"), booktabs=T)%>%
kable_styling(latex_options=c("scale_down", "hold_position"))
kable(filter(full_results, grepl("SLC22", Symbol)), booktabs=T)%>%
kable_styling(latex_options=c("scale_down", "hold_position"))
group=as.factor(sampleInfo$group)
##### GLIMMA ########3
#BiocManager::install("Glimma")
library(Glimma)
library(edgeR)
cpm <- cpm(edata)
lcpm <- cpm(edata, log=TRUE)
d <-glMDPlot(tfit, coef=1, status=dt, main=colnames(tfit)[1],
side.main="Entrez_Gene_ID", counts=edata, groups=group, path = "..", launch=TRUE)
d
library(readr)
filter(full_results, adj.P.Val < 0.05, abs(logFC) >1) %>%
write.csv(file ="./results/filtered_GSE75037.csv")
sessionInfo()
library(htmlwidgets)
htmlwidgets::saveWidget(d, "GSE75037-plot.html", selfcontained = T)
library(htmlwidgets)
htmlwidgets::saveWidget(d, "gse75-plot.html", selfcontained = T)
saveWidget(d, "gse75-plot.html", selfcontained = T)
d <-glMDPlot(tfit, coef=1, status=dt, main=colnames(tfit)[1],
side.main="Entrez_Gene_ID", counts=edata, groups=group, path = ".",folder = "glimma-plots", html = "GSE75037-Plot", launch=TRUE)
# set options for R markdown knitting
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(linewidth=80)
# set up line wrapping in MD knit output
library(knitr)
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options)
{
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth))
{
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n))
x = strwrap(x, width = n)
x = paste(x, collapse = "\n")
}
hook_output(x, options)
})
#### Example code to install packages
#install.packages("data.table")
#### Load required libraries
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(dplyr)
transactionData <- data.table(read_excel("QVI_transaction_data.xlsx"))
setwd("~/Documents/Github/Quantium_Data Analytics_Virtual_Experience_Program")
# set options for R markdown knitting
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(linewidth=80)
# set up line wrapping in MD knit output
library(knitr)
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options)
{
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth))
{
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n))
x = strwrap(x, width = n)
x = paste(x, collapse = "\n")
}
hook_output(x, options)
})
#### Example code to install packages
#install.packages("data.table")
#### Load required libraries
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(dplyr)
transactionData <- data.table(read_excel("QVI_transaction_data.xlsx"))
# set options for R markdown knitting
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(linewidth=80)
# set up line wrapping in MD knit output
library(knitr)
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options)
{
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth))
{
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n))
x = strwrap(x, width = n)
x = paste(x, collapse = "\n")
}
hook_output(x, options)
})
#### Example code to install packages
#install.packages("data.table")
#### Load required libraries
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(readxl)
library(dplyr)
#### Point the filePath to where you have downloaded the datasets to and
#### assign the data files to data.tables
transactionData <- data.table(read_excel("QVI_transaction_data.xlsx"))
customerData <- fread("QVI_purchase_behaviour.csv")
#### Examine transaction data
str(transactionData)
#### Convert DATE column to a date format
#### A quick search online tells us that CSV and Excel integer dates begin on 30Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899-12-30")
#### Examine transaction data
head(transactionData)
#### Examine PROD_NAME
transactionData[, .N, PROD_NAME]
#### Examine the words in PROD_NAME to see if there are any incorrect entries
#### such as products that are not chips
productWords <- data.table(unlist(strsplit(unique(transactionData[, PROD_NAME]), " ")))
setnames(productWords, 'words')
#### Removing digits
productWords <- productWords[grepl("\\d", words) == FALSE, ]
#### Removing special characters
productWords <- productWords[grepl("[:alpha:]", words), ]
#### Let's look at the most common words by counting the number of times a wordappears and
#### sorting them by this frequency in order of highest to lowest frequency
productWords[, .N, words][order(N, decreasing = TRUE)]
#### Remove salsa products
transactionData[, SALSA := grepl("salsa", tolower(PROD_NAME))]
transactionData <- transactionData[SALSA == FALSE, ][, SALSA := NULL]
#### Summarise the data to check for nulls and possible outliers
summary(transactionData)
sum(is.na(transactionData))
#### Filter the dataset to find the outlier
outlier <- transactionData[PROD_QTY == 200,]
#### Let's see if the customer has had other transactions
#### Filter out the customer based on the loyalty card number
outlierTransactions <- transactionData[LYLTY_CARD_NBR == 226000,]
#### Re-examine transaction data
numberOfTransactionsByDate <- data.frame(sort(table(transactionData$DATE),decreasing = TRUE ))
setnames(numberOfTransactionsByDate,c('date','freq'))
numberOfTransactionsByDate<-numberOfTransactionsByDate[order(as.Date(numberOfTransactionsByDate$date)),]
#### Count the number of transactions by date
unique(transactionData$DATE)
summary(transactionData$DATE)
#### Create a sequence of dates and join this the count of transactions by date
# Over to you - create a column of dates that includes every day from 1 Jul 2018 to
#30 Jun 2019, and join it onto the data to fill in the missing day.
seqOfDates <- data.table(seq(as.Date('2018-07-01'),as.Date('2019-06-30'),by = 1))
setnames(seqOfDates,"date")
seqOfDates$date <- as.factor(seqOfDates$date)
class(seqOfDates$date)
class(numberOfTransactionsByDate$date)
transactions_by_day <- merge (x = seqOfDates, y = numberOfTransactionsByDate, by="date", all.x = TRUE)
transactions_by_day[is.na(transactions_by_day)] <- 0
transactions_by_day$date <- as.Date(transactions_by_day$date)
#### Setting plot themes to format graphs
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
#### Plot transactions over time
ggplot(transactions_by_day, aes(x = date, y = freq)) +
geom_line() +
labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
scale_x_date(breaks = "1 month") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Filter to December and look at individual days
december <- transactions_by_day[transactions_by_day$date >= as.Date("2018-12-01") & transactions_by_day$date <= as.Date("2018-12-31"),]
#### plotting transactions over december
ggplot(december,aes(x=date,y= freq)) +
geom_line() +
labs(x = "Day", y ="Number of transactions",title="Transactions over time (December)")+
scale_x_date(breaks = "1 day") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Always check your output
transactionData[, PACK_SIZE := parse_number(PROD_NAME)]
#### Let's check if the pack sizes look sensible
transactionData[, .N, PACK_SIZE][order(PACK_SIZE)]
#### Let's plot a histogram of PACK_SIZE since we know that it is a categorical
#variable and not a continuous variable even though it is numeric.
ggplot(transactionData,aes(x=PACK_SIZE) )+
geom_histogram(binwidth = 10,color="black",fill="lightblue") +scale_x_discrete() +
labs(x = "Pack Sizes", y ="Frequency",title="Histogram of Pack Sizes")+scale_color_brewer(palette="Dark2")+geom_density(alpha=.2, fill="#FF6666") #### mean and standard deviation of pack sizes
mean(transactionData$PACK_SIZE)
sd(transactionData$PACK_SIZE)
#### Brands
transactionData$BRAND_NAME <- sub('(^\\w+)\\s.+','\\1',transactionData$PROD_NAME)
#### Checking brands
# Over to you! Check the results look reasonable.
#### Clean brand names
transactionData[BRAND_NAME == "RED", BRAND_NAME := "RRD"]
transactionData[BRAND_NAME == "GRAIN", BRAND_NAME := "GrnWves"]
transactionData[BRAND_NAME == "INFZNS", BRAND_NAME := "Infuzions"]
transactionData[BRAND_NAME == "WW", BRAND_NAME := "Woolworths"]
transactionData[BRAND_NAME == "SNBTS", BRAND_NAME := "Sunbites"]
#### table
transactionData[, .N, by = BRAND_NAME][order(BRAND_NAME)]
#### Check again
brands <- data.frame(sort(table(transactionData$BRAND_NAME),decreasing = TRUE ))
setnames(brands,c("BRAND","freq"))
ggplot(brands,aes(x=BRAND,y= freq,fill=BRAND)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "Brands", y ="Frequency",title="Distribution Of Brand Purchases")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Examining customer data
summary(customerData)
sum(is.na(customerData))
lifestageCategory <- data.frame(sort(table(customerData$LIFESTAGE),decreasing = TRUE ))
setnames(lifestageCategory,c("lifestage","freq"))
ggplot(lifestageCategory,aes(x=lifestage,y= freq,fill=lifestage)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "lifestage", y ="frequency",title="Distribution Of Customers Over Lifestages")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+scale_fill_brewer(palette="Dark2")
premiumCustomerType <- data.frame(sort(table(customerData$PREMIUM_CUSTOMER),decreasing = TRUE ))
setnames(premiumCustomerType,c("premium_customer_type","freq"))
ggplot(premiumCustomerType,aes(x=premium_customer_type,y= freq,fill=premium_customer_type)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "lifestage", y ="frequency",title="Distribution Of Customers Over Premium Types")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+scale_fill_brewer(palette="Dark2")
#### Merge transaction data to customer data
data <- merge(transactionData, customerData, all.x = TRUE)
sum(is.na(data))
fwrite(data, "QVI_data.csv")
#### Total sales by LIFESTAGE and PREMIUM_CUSTOMER
sales <- data[, .(SALES = sum(TOT_SALES)), .(LIFESTAGE, PREMIUM_CUSTOMER)]
#### Create plot
p <- ggplot(data = sales) +
geom_mosaic(aes(weight = SALES, x = product(PREMIUM_CUSTOMER, LIFESTAGE), fill = PREMIUM_CUSTOMER)) +
labs(x = "Lifestage", y = "Premium customer flag", title = "Proportion of sales") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Plot and label with proportion of sales
p + geom_text(data = ggplot_build(p)$data[[1]], aes(x = (xmin + xmax)/2 , y =
(ymin + ymax)/2, label = as.character(paste(round(.wt/sum(.wt),3)*100,
'%'))))
#### Number of customers by LIFESTAGE and PREMIUM_CUSTOMER
customers <- data[, .(CUSTOMERS = uniqueN(LYLTY_CARD_NBR)), .(LIFESTAGE, PREMIUM_CUSTOMER)][order(-CUSTOMERS)]
#### Create plot
p <- ggplot(data = customers) +
geom_mosaic(aes(weight = CUSTOMERS, x = product(PREMIUM_CUSTOMER, LIFESTAGE), fill = PREMIUM_CUSTOMER)) +
labs(x = "Lifestage", y = "Premium customer flag", title = "Proportion of customers") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Plot and label with proportion of customers
p + geom_text(data = ggplot_build(p)$data[[1]], aes(x = (xmin + xmax)/2 , y =
(ymin + ymax)/2, label = as.character(paste(round(.wt/sum(.wt),3)*100,
'%'))))
#### Average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
avg_units <- data[, .(AVG = sum(PROD_QTY)/uniqueN(LYLTY_CARD_NBR)),.(LIFESTAGE, PREMIUM_CUSTOMER)][order(-AVG)]
#### Create plot
ggplot(data = avg_units, aes(weight = AVG, x = LIFESTAGE, fill =PREMIUM_CUSTOMER)) +
geom_bar(position = position_dodge()) +
labs(x = "Lifestage", y = "Avg units per transaction", title = "Units percustomer") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Average price per unit by LIFESTAGE and PREMIUM_CUSTOMER
avg_price <- data[, .(AVG = sum(TOT_SALES)/sum(PROD_QTY)), .(LIFESTAGE,PREMIUM_CUSTOMER)][order(-AVG)]
#### Create plot
ggplot(data = avg_price, aes(weight = AVG, x = LIFESTAGE, fill =PREMIUM_CUSTOMER)) +
geom_bar(position = position_dodge()) +
labs(x = "Lifestage", y = "Avg price per unit", title = "Price per unit") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Perform an independent t-test between mainstream vs premium and budget midageand
#### young singles and couples
pricePerUnit <- data[, price := TOT_SALES/PROD_QTY]
t.test(data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES") & PREMIUM_CUSTOMER == "Mainstream", price], data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES") & PREMIUM_CUSTOMER != "Mainstream", price], alternative = "greater")
#### Deep dive into Mainstream, young singles/couples
segment1<- data[LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER == "Mainstream",]
other <- data[!(LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER == "Mainstream"),]
#### Brand affinity compared to the rest of the population
quantity_segment1 <- segment1[, sum(PROD_QTY)]
quantity_other <- other[, sum(PROD_QTY)]
quantity_segment1_by_brand <- segment1[, .(targetSegment = sum(PROD_QTY)/quantity_segment1), by = BRAND_NAME]
quantity_other_by_brand <- other[, .(other = sum(PROD_QTY)/quantity_other), by = BRAND_NAME]
brand_proportions <- merge(quantity_segment1_by_brand, quantity_other_by_brand)[, affinityToBrand := targetSegment/other]
brand_proportions[order(-affinityToBrand)]
#### Preferred pack size compared to the rest of the population
quantity_segment1_by_pack <- segment1[, .(targetSegment = sum(PROD_QTY)/quantity_segment1), by = PACK_SIZE]
quantity_other_by_pack <- other[, .(other = sum(PROD_QTY)/quantity_other), by =PACK_SIZE]
pack_proportions <- merge(quantity_segment1_by_pack, quantity_other_by_pack)[, affinityToPack := targetSegment/other]
pack_proportions[order(-affinityToPack)]
# set options for R markdown knitting
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(linewidth=80)
# set up line wrapping in MD knit output
library(knitr)
hook_output = knit_hooks$get("output")
knit_hooks$set(output = function(x, options)
{
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth))
{
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n))
x = strwrap(x, width = n)
x = paste(x, collapse = "\n")
}
hook_output(x, options)
})
#### Example code to install packages
#install.packages("data.table")
#### Load required libraries
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(readxl)
library(dplyr)
#### Point the filePath to where you have downloaded the datasets to and
#### assign the data files to data.tables
transactionData <- data.table(read_excel("QVI_transaction_data.xlsx"))
customerData <- fread("QVI_purchase_behaviour.csv")
#### Examine transaction data
str(transactionData)
#### Convert DATE column to a date format
#### A quick search online tells us that CSV and Excel integer dates begin on 30Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899-12-30")
#### Examine transaction data
head(transactionData)
#### Examine PROD_NAME
transactionData[, .N, PROD_NAME]
#### Examine the words in PROD_NAME to see if there are any incorrect entries
#### such as products that are not chips
productWords <- data.table(unlist(strsplit(unique(transactionData[, PROD_NAME]), " ")))
setnames(productWords, 'words')
#### Removing digits
productWords <- productWords[grepl("\\d", words) == FALSE, ]
#### Removing special characters
productWords <- productWords[grepl("[:alpha:]", words), ]
#### Let's look at the most common words by counting the number of times a wordappears and
#### sorting them by this frequency in order of highest to lowest frequency
productWords[, .N, words][order(N, decreasing = TRUE)]
#### Remove salsa products
transactionData[, SALSA := grepl("salsa", tolower(PROD_NAME))]
transactionData <- transactionData[SALSA == FALSE, ][, SALSA := NULL]
#### Summarise the data to check for nulls and possible outliers
summary(transactionData)
#### Filter the dataset to find the outlier
outlier <- transactionData[PROD_QTY == 200,]
#### Let's see if the customer has had other transactions
transactionData[LYLTY_CARD_NBR == 226000, ]
#### Filter out the customer based on the loyalty card number
transactionData <‐ transactionData[LYLTY_CARD_NBR != 226000, ]
#### Filter out the customer based on the loyalty card number
transactionData <- transactionData[LYLTY_CARD_NBR != 226000, ]
#### Re‐examine transaction data
summary(transactionData)
#### Count the number of transactions by date
transactionData[, .N, by = DATE]
#### Create a sequence of dates and join this the count of transactions by date
# Over to you - create a column of dates that includes every day from 1 Jul 2018 to
#30 Jun 2019, and join it onto the data to fill in the missing day.
allDates <- data.table(seq(as.Date("2018/07/01"), as.Date("2019/06/30"), by ="day"))
setnames(allDates, "DATE")
transactions_by_day <- merge(allDates, transactionData[, .N, by = DATE], all.x = TRUE)
#### Setting plot themes to format graphs
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
#### Plot transactions over time
ggplot(transactions_by_day, aes(x = DATE, y = N)) +
geom_line() +
labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
scale_x_date(breaks = "1 month") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Filter to December and look at individual days
ggplot(transactions_by_day[month(DATE) == 12, ], aes(x = DATE, y = N)) +
geom_line() +
labs(x = "Day", y = "Number of transactions", title = "Transactions over
↪ time") +
scale_x_date(breaks = "1 day") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Always check your output
transactionData[, PACK_SIZE := parse_number(PROD_NAME)]
#### Let's check if the pack sizes look sensible
transactionData[, .N, PACK_SIZE][order(PACK_SIZE)]
#### Let's check the output of the first few rows to see if we have indeedpicked out p
head(transactionData)
#### Let's plot a histogram of PACK_SIZE since we know that it is a categorical
#variable and not a continuous variable even though it is numeric.
hist(transactionData[, PACK_SIZE])
#### Brands
transactionData[, BRAND_NAME := toupper(substr(PROD_NAME, 1, regexpr(pattern = ' ', PROD_NAME) - 1))]
#### Checking brands
transactionData[, .N, by = BRAND_NAME][order(-N)]
#### Checking brands
# Over to you! Check the results look reasonable.
#### Clean brand names
transactionData[BRAND_NAME == "RED", BRAND_NAME := "RRD"]
transactionData[BRAND_NAME == "GRAIN", BRAND_NAME := "GrnWves"]
transactionData[BRAND_NAME == "INFZNS", BRAND_NAME := "Infuzions"]
transactionData[BRAND_NAME == "WW", BRAND_NAME := "Woolworths"]
transactionData[BRAND_NAME == "SNBTS", BRAND_NAME := "Sunbites"]
#### table
transactionData[, .N, by = BRAND_NAME][order(BRAND_NAME)]
#### Check again
brands <- data.frame(sort(table(transactionData$BRAND_NAME),decreasing = TRUE ))
setnames(brands,c("BRAND","freq"))
ggplot(brands,aes(x=BRAND,y= freq,fill=BRAND)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "Brands", y ="Frequency",title="Distribution Of Brand Purchases")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Examining customer data
summary(customerData)
sum(is.na(customerData))
lifestageCategory <- data.frame(sort(table(customerData$LIFESTAGE),decreasing = TRUE ))
setnames(lifestageCategory,c("lifestage","freq"))
ggplot(lifestageCategory,aes(x=lifestage,y= freq,fill=lifestage)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "lifestage", y ="frequency",title="Distribution Of Customers Over Lifestages")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+scale_fill_brewer(palette="Dark2")
premiumCustomerType <- data.frame(sort(table(customerData$PREMIUM_CUSTOMER),decreasing = TRUE ))
setnames(premiumCustomerType,c("premium_customer_type","freq"))
ggplot(premiumCustomerType,aes(x=premium_customer_type,y= freq,fill=premium_customer_type)) +
geom_bar(stat="identity",width = 0.5) +
labs(x = "lifestage", y ="frequency",title="Distribution Of Customers Over Premium Types")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+scale_fill_brewer(palette="Dark2")
#### Merge transaction data to customer data
data <- merge(transactionData, customerData, all.x = TRUE)
sum(is.na(data))
fwrite(data, "QVI_data.csv")
#### Total sales by LIFESTAGE and PREMIUM_CUSTOMER
sales <- data[, .(SALES = sum(TOT_SALES)), .(LIFESTAGE, PREMIUM_CUSTOMER)]
#### Create plot
p <- ggplot(data = sales) +
geom_mosaic(aes(weight = SALES, x = product(PREMIUM_CUSTOMER, LIFESTAGE), fill = PREMIUM_CUSTOMER)) +
labs(x = "Lifestage", y = "Premium customer flag", title = "Proportion of sales") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Plot and label with proportion of sales
p + geom_text(data = ggplot_build(p)$data[[1]], aes(x = (xmin + xmax)/2 , y =
(ymin + ymax)/2, label = as.character(paste(round(.wt/sum(.wt),3)*100,
'%'))))
#### Number of customers by LIFESTAGE and PREMIUM_CUSTOMER
customers <- data[, .(CUSTOMERS = uniqueN(LYLTY_CARD_NBR)), .(LIFESTAGE, PREMIUM_CUSTOMER)][order(-CUSTOMERS)]
#### Create plot
p <- ggplot(data = customers) +
geom_mosaic(aes(weight = CUSTOMERS, x = product(PREMIUM_CUSTOMER, LIFESTAGE), fill = PREMIUM_CUSTOMER)) +
labs(x = "Lifestage", y = "Premium customer flag", title = "Proportion of customers") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Plot and label with proportion of customers
p + geom_text(data = ggplot_build(p)$data[[1]], aes(x = (xmin + xmax)/2 , y =
(ymin + ymax)/2, label = as.character(paste(round(.wt/sum(.wt),3)*100,
'%'))))
#### Average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
avg_units <- data[, .(AVG = sum(PROD_QTY)/uniqueN(LYLTY_CARD_NBR)),.(LIFESTAGE, PREMIUM_CUSTOMER)][order(-AVG)]
#### Create plot
ggplot(data = avg_units, aes(weight = AVG, x = LIFESTAGE, fill =PREMIUM_CUSTOMER)) +
geom_bar(position = position_dodge()) +
labs(x = "Lifestage", y = "Avg units per transaction", title = "Units percustomer") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Average price per unit by LIFESTAGE and PREMIUM_CUSTOMER
avg_price <- data[, .(AVG = sum(TOT_SALES)/sum(PROD_QTY)), .(LIFESTAGE,PREMIUM_CUSTOMER)][order(-AVG)]
#### Create plot
ggplot(data = avg_price, aes(weight = AVG, x = LIFESTAGE, fill =PREMIUM_CUSTOMER)) +
geom_bar(position = position_dodge()) +
labs(x = "Lifestage", y = "Avg price per unit", title = "Price per unit") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Perform an independent t-test between mainstream vs premium and budget midageand
#### young singles and couples
pricePerUnit <- data[, price := TOT_SALES/PROD_QTY]
t.test(data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES") & PREMIUM_CUSTOMER == "Mainstream", price], data[LIFESTAGE %in% c("YOUNG SINGLES/COUPLES", "MIDAGE SINGLES/COUPLES") & PREMIUM_CUSTOMER != "Mainstream", price], alternative = "greater")
#### Deep dive into Mainstream, young singles/couples
segment1<- data[LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER == "Mainstream",]
other <- data[!(LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER == "Mainstream"),]
#### Brand affinity compared to the rest of the population
quantity_segment1 <- segment1[, sum(PROD_QTY)]
quantity_other <- other[, sum(PROD_QTY)]
quantity_segment1_by_brand <- segment1[, .(targetSegment = sum(PROD_QTY)/quantity_segment1), by = BRAND_NAME]
quantity_other_by_brand <- other[, .(other = sum(PROD_QTY)/quantity_other), by = BRAND_NAME]
brand_proportions <- merge(quantity_segment1_by_brand, quantity_other_by_brand)[, affinityToBrand := targetSegment/other]
brand_proportions[order(-affinityToBrand)]
#### Preferred pack size compared to the rest of the population
quantity_segment1_by_pack <- segment1[, .(targetSegment = sum(PROD_QTY)/quantity_segment1), by = PACK_SIZE]
quantity_other_by_pack <- other[, .(other = sum(PROD_QTY)/quantity_other), by =PACK_SIZE]
pack_proportions <- merge(quantity_segment1_by_pack, quantity_other_by_pack)[, affinityToPack := targetSegment/other]
pack_proportions[order(-affinityToPack)]
